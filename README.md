# AI ì „ê³µíŠ¹í™”êµìœ¡ í”„ë¡œê·¸ë¨
**ì €ì ìŠ¤íƒ€ì¼ ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„± ë° ë¬¸ì²´ì— ë”°ë¥¸ ê°ì„± ë¶„ì„ ì°¨ì´**

<br/>

## ğŸ“– í”„ë¡œì íŠ¸ ì†Œê°œ
ì´ í”„ë¡œì íŠ¸ëŠ” íŠ¹ì • ì‘ê°€ì˜ ë¬¸ì²´ë¥¼ í•™ìŠµí•œ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸(GPT-2)ì„ êµ¬ì¶•í•˜ê³ , ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì²´ì™€ ê°ì„± í‘œí˜„ ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. 


<br/>

* íŠ¹ì • ì‘ê°€ì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë¬¸ì²´ë¥¼ ë°˜ì˜í•œ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ êµ¬ì¶•
  
* ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ BLEU ì ìˆ˜ ë° ê°ì„± ë¶„í¬ ë¶„ì„
  
* ë¬¸ì²´ ë³´ì¡´ ì—¬ë¶€ê°€ ê°ì„± ë¶„ì„ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ íƒêµ¬
<br/>

----
### ğŸš€ ì½”ë“œ ìˆ˜í–‰ ê³¼ì •
1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
  * ë°ì´í„° ì¶œì²˜: ë°ì´ì½˜ - ì†Œì„¤ ë¬¸ì¥ ë­‰ì¹˜ ë°ì´í„° ì´ìš© 
  * ë¬¸ì¥ ì–¸ì–´: ì˜ì–´ 


* ì „ì²˜ë¦¬:
  - íŠ¹ìˆ˜ë¬¸ìì™€ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
  - ì‰¼í‘œ, ë§ˆì¹¨í‘œ ë“± ë¬¸ì²´ ë³´ì¡´ì— ì¤‘ìš”í•œ êµ¬ë‘ì  ìœ ì§€
  - ê°ì„± ë¼ë²¨ë§: TextBlobìœ¼ë¡œ Positive, Neutral, Negativeë¡œ ë¶„ë¥˜í•˜ê³  ìˆ«ìë¡œ ë§¤í•‘

  #####    ë¬¸ì²´ ë³´ì¡´ ì „ì²˜ë¦¬ í•¨ìˆ˜
  ```
  def clean_text_preserve_style(text):
      import re
      text = re.sub(r"[^\w\s.,!?']", "", text)  # íŠ¹ìˆ˜ë¬¸ì ìœ ì§€
      text = re.sub(r"\s+", " ", text).strip()  # ê³µë°± ì œê±°
      return text
  ```

  
2. ë¬¸ì²´ í•™ìŠµ ëª¨ë¸(GPT-2 Fine-Tuning)
ëª¨ë¸ êµ¬ì„±:
  - Hugging Faceì˜ GPT-2 ëª¨ë¸ì„ ì‚¬ìš©
  - íŠ¹ì • ì‘ê°€(author=3)ì˜ ë°ì´í„°ë¥¼ í•™ìŠµ
  - í•™ìŠµ ë°ì´í„°(90%), í‰ê°€ ë°ì´í„°(10%)ë¡œ ë¶„í•  í›„ Fine-tuning

    
  - ëª¨ë¸ í•™ìŠµ:
  - í•™ìŠµ ì†ì‹¤ ê°ì†Œ: ë§ˆì§€ë§‰ Epoch ê¸°ì¤€ 0.328
  - BLEU ì ìˆ˜ - ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

    
  - í…ìŠ¤íŠ¸ ìƒì„±:
  - í”„ë¡¬í”„íŠ¸ [We, The day was bright, she] ì…ë ¥ ì‹œ í…ìŠ¤íŠ¸ ìƒì„±
  - We have no doubt about that, but I am sure you may very well be quite right.


    ##### GPT-2 ëª¨ë¸ í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸
    ```
    text_generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
    generated_text = text_generator("she", max_length=100, num_return_sequences=1)
    print("Generated Text:", generated_text[0]["generated_text"])
    ```


3. ê°ì„± ë¶„ì„ ëª¨ë¸(DistilBERT)
ëª¨ë¸ êµ¬ì„±:
  * TextBlob ê°ì„± ë¶„ì„ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ DistilBERT ê¸°ë°˜ ê°ì„± ë¶„ì„ ëª¨ë¸ êµ¬ì¶•
  * í•™ìŠµ ë°ì´í„°(80%), ê²€ì¦ ë°ì´í„°(10%), í…ŒìŠ¤íŠ¸ ë°ì´í„°(10%)ë¡œ ë¶„í• 
  * ëª¨ë¸ í•™ìŠµ ë° í‰ê°€:
  * ë¬¸ì²´ ë°˜ì˜ ëª¨ë¸(Accuracy): 22.8%
  * ë¬¸ì²´ ë¯¸ë°˜ì˜ ëª¨ë¸(Accuracy): 04.1%
  * Precision, Recall, F1-scoreë¥¼ í†µí•´ ê°ì„± ë¶„ì„ ì„±ëŠ¥ í‰ê°€


    ```
    # Trainer ì •ì˜ ë° í•™ìŠµ
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics
    )
    trainer.train()
    ```

4. ë¬¸ì²´ ì—°ê´€ ê°ì„± ë¶„ì„ ê²°ê³¼


- í•™ìŠµëª¨ë¸
* í‰ê·  BLEU Score: 0.015~0.4
* ê°ì„± ë¶„ì„ ë¶„í¬:
* Positive: 1ê±´
* Negative: 2ê±´


- ë¹„í•™ìŠµëª¨ë¸
* í‰ê·  BLEU Score: 0.015~0.2
* ê°ì„± ë¶„ì„ ë¶„í¬:
* Positive: 1ê±´
* Negative: 2ê±´


<br/>


## ğŸ” ì£¼ìš” ì‹¤í—˜ ê²°ê³¼
### 1.ë¬¸ì²´ í•™ìŠµ ëª¨ë¸(GPT-2)
  - í”„ë¡¬í”„íŠ¸	ìƒì„± í…ìŠ¤íŠ¸ (Generated Text)	í‰ê·  BLEU Score: 0.0657

--------------------------------------------------
--- Prompt: We ---


Generated Text: We have no doubt about that, but....


BLEU Score: 0.7977


--------------------------------------------------
--- Prompt: The day was bright ---

Generated Text: The day was bright, the clouds were thick, ....


BLEU Score: 0.6921

--------------------------------------------------
--- Prompt: she ---


Generated Text: she, odin, my dear odin, I beg you to....


BLEU Score: 0.8452

--------------------------------------------------

### 2.í•™ìŠµ ëª¨ë¸ê³¼ ë¹„í•™ìŠµ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ

--------------------------------------------------
--- Comparison for Prompt 1 ---
Prompt: We

Trained Model:
Generated Text: We have seen your letter and all....


Sentiment: Positive


BLEU Score: 0.2287


Untrained Model:
Generated Text: We just hope you understand and respect the...


Sentiment: Negative


BLEU Score: 0.0410

--------------------------------------------------

--- Comparison for Prompt 2 ---
Prompt: The day was bright

Trained Model:
Generated Text: The day was bright, bright as ever,.....


Sentiment: Negative


BLEU Score: 0.0657






Untrained Model:
Generated Text: The day was bright, dark, and beautiful," he added...


Sentiment: Positive


BLEU Score: 0.0695

--------------------------------------------------

--- Comparison for Prompt 3 ---
Prompt: she

Trained Model:
Generated Text: she was only eleven years old.....


Sentiment: Negative


BLEU Score: 0.1968




Untrained Model:
Generated Text: she would go. The next morning,.....


Sentiment: Negative


BLEU Score: 0.1400


--------------------------------------------------


## ğŸ›  í•œê³„ ë° ê°œì„  ë°©í–¥
### í•œê³„
  - BLEU ì ìˆ˜ê°€ ì¼ë¶€ í”„ë¡¬í”„íŠ¸ì—ì„œ ë‚®ê²Œ ì¸¡ì •ë¨
    -   â†’ ì°¸ì¡° ë¬¸ì¥ ë‹¤ì–‘ì„± ë¶€ì¡±
  - ê°ì„± ë¶„ì„ ëª¨ë¸ì˜ ì„±ëŠ¥ ì €ì¡°
    - â†’ ë¼ë²¨ë§ ë° ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ
  - ë¬¸ì²´ì™€ ê°ì„± ê°„ ê´€ê³„ë¥¼ ëª…í™•íˆ ì…ì¦í•˜ì§€ ëª»í•¨
    

### ê°œì„  ë°©í–¥
  - ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ í™œìš©:
  - ë°ì´í„° ì¦ê°•ì„ í†µí•´ ë°ì´í„° í™•ë³´
  - í‰ê°€ ì§€í‘œ ë³´ì™„:
  - BLEU ì™¸ì— ROUGE, BERTScore ë“± ì¶”ê°€ ì§€í‘œ í™œìš©
  - ë¼ë²¨ë§ ê°œì„  ë° ë°ì´í„° ì¦ê°•:
  - ê°ì • ë¼ë²¨ë§ ê³ ë„í™” ë° ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°
<br/>

### ğŸ“š ì°¸ê³ ë¬¸í—Œ


Radford, A., et al., 2019. "Language Models are Few-Shot Learners," Advances in Neural Information Processing Systems.


Zhang, T., et al., 2021. "Style Example-Guided Text Generation using Generative Adversarial Transformers," Journal of Computational Linguistics.
<br/>


## ğŸ“ ì‹¤í–‰ ë°©ë²•
í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:
- pip install datasets transformers textblob nltk


- Google Driveì—ì„œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬.


- train.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ìˆ˜í–‰.


- generate.pyë¡œ í…ìŠ¤íŠ¸ ìƒì„± ë° BLEU ì ìˆ˜ ê³„ì‚°.
